{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets headline and description paragraph from nasa news\n",
    "def scrape_mars_news():\n",
    "    browser=init_browser()\n",
    "    mars_news = \"https://mars.nasa.gov/news/\"\n",
    "\n",
    "    browser.visit(mars_news)\n",
    "    mars_html = browser.html\n",
    "    soup = bs(mars_html,'lxml')\n",
    "    sleep(1)\n",
    "    headline = soup.find('ul',class_='item_list').find('div',class_=\"content_title\").find('a').text\n",
    "    paragraph = soup.find('ul',class_='item_list').find('div',class_=\"article_teaser_body\").text\n",
    "    \n",
    "    sleep(2)\n",
    "    browser.quit()\n",
    "    return (headline,paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets current display image from JPL spaceimages\n",
    "def scrape_jpl():\n",
    "    browser=init_browser()\n",
    "    jpl_images = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    jpl_root = \"https://www.jpl.nasa.gov\"\n",
    "\n",
    "    browser.visit(jpl_images)\n",
    "    jpl_html = browser.html\n",
    "    soup = bs(jpl_html,'lxml')\n",
    "    featured_image_url = jpl_root+soup.find('section',class_='main_feature').find(\"div\",class_=\"carousel_items\").\\\n",
    "                            find('article')['style'].split(\"'\")[1]\n",
    "    sleep(2)\n",
    "    browser.quit()\n",
    "    return featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapes the weather on mars from twitter\n",
    "def weather_on_mars():\n",
    "    #SOURCE: https://medium.com/@dawranliou/twitter-scraper-tutorial-with-python-requests-beautifulsoup-and-selenium-part-2-b38d849b07fe\n",
    "    driver = webdriver.Chrome()\n",
    "    mars_twitter = \"https://twitter.com/marswxreport\"\n",
    "    driver.get(mars_twitter)\n",
    "    sleep(2)\n",
    "    body = driver.find_element_by_tag_name('body')\n",
    "\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "\n",
    "    mars_twitter_html = driver.page_source\n",
    "    soup = bs(mars_twitter_html,'lxml')\n",
    "    \n",
    "    for result in soup.find_all(class_='css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0'):\n",
    "        text = result.text\n",
    "        if text.split(\" \")[0]=='InSight':\n",
    "            sleep(2)\n",
    "            browser.quit()\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_facts():\n",
    "    facts_table = pd.read_html(\"https://space-facts.com/mars/\")[0]\n",
    "    facts_table = facts_table.rename(columns={0:'Measurement',1:\"Mars\"})\n",
    "    mars_facts = facts_table.to_html(index=False)\n",
    "    return mars_facts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_hemispheres(): \n",
    "    browser = init_browser()\n",
    "    root_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "    browser.visit(root_url)\n",
    "    browser_html = browser.html\n",
    "\n",
    "\n",
    "    soup = bs(browser_html,'lxml')\n",
    "    a_list = soup.find_all(class_=\"itemLink product-item\")\n",
    "\n",
    "    urls = ['https://astrogeology.usgs.gov' + end_url for end_url in list(set([x['href'] for x in a_list]))]\n",
    "    titles = [x.text for x in soup.find_all('h3')]\n",
    "    url_title = {titles[i]:urls[i] for i in range(4)}\n",
    "\n",
    "\n",
    "    results = []\n",
    "    for title in url_title:\n",
    "        url = url_title[title]\n",
    "        browser.visit(url)\n",
    "        browser_html = browser.html\n",
    "        soup=bs(browser_html,'lxml')\n",
    "        big_url = soup.find(class_='downloads').find_all('a')[1]['href']\n",
    "        results.append({'title':title,'img_url':big_url})\n",
    "\n",
    "    sleep(1)\n",
    "    browser.quit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
